# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: llm.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\tllm.proto\x12\x03llm\"\x97\x01\n\x11\x43ompletionRequest\x12\x0e\n\x06prompt\x18\x01 \x01(\t\x12\x0e\n\x06length\x18\x02 \x01(\x05\x12\x13\n\x0btemperature\x18\x03 \x01(\x02\x12\r\n\x05top_k\x18\x04 \x01(\x02\x12\r\n\x05top_p\x18\x05 \x01(\x02\x12\x1a\n\x12repetition_penalty\x18\x06 \x01(\x02\x12\x13\n\x0bstop_tokens\x18\x07 \x03(\t\"&\n\x12\x43ompletionResponse\x12\x10\n\x08response\x18\x01 \x01(\t\"\x1e\n\x0c\x45mbedRequest\x12\x0e\n\x06prompt\x18\x01 \x01(\t\"\x1e\n\rEmbedResponse\x12\r\n\x05\x65mbed\x18\x01 \x03(\x02\x32z\n\x03LLM\x12\x41\n\x08\x43omplete\x12\x16.llm.CompletionRequest\x1a\x17.llm.CompletionResponse\"\x00(\x01\x30\x01\x12\x30\n\x05\x45mbed\x12\x11.llm.EmbedRequest\x1a\x12.llm.EmbedResponse\"\x00\x62\x06proto3')



_COMPLETIONREQUEST = DESCRIPTOR.message_types_by_name['CompletionRequest']
_COMPLETIONRESPONSE = DESCRIPTOR.message_types_by_name['CompletionResponse']
_EMBEDREQUEST = DESCRIPTOR.message_types_by_name['EmbedRequest']
_EMBEDRESPONSE = DESCRIPTOR.message_types_by_name['EmbedResponse']
CompletionRequest = _reflection.GeneratedProtocolMessageType('CompletionRequest', (_message.Message,), {
  'DESCRIPTOR' : _COMPLETIONREQUEST,
  '__module__' : 'llm_pb2'
  # @@protoc_insertion_point(class_scope:llm.CompletionRequest)
  })
_sym_db.RegisterMessage(CompletionRequest)

CompletionResponse = _reflection.GeneratedProtocolMessageType('CompletionResponse', (_message.Message,), {
  'DESCRIPTOR' : _COMPLETIONRESPONSE,
  '__module__' : 'llm_pb2'
  # @@protoc_insertion_point(class_scope:llm.CompletionResponse)
  })
_sym_db.RegisterMessage(CompletionResponse)

EmbedRequest = _reflection.GeneratedProtocolMessageType('EmbedRequest', (_message.Message,), {
  'DESCRIPTOR' : _EMBEDREQUEST,
  '__module__' : 'llm_pb2'
  # @@protoc_insertion_point(class_scope:llm.EmbedRequest)
  })
_sym_db.RegisterMessage(EmbedRequest)

EmbedResponse = _reflection.GeneratedProtocolMessageType('EmbedResponse', (_message.Message,), {
  'DESCRIPTOR' : _EMBEDRESPONSE,
  '__module__' : 'llm_pb2'
  # @@protoc_insertion_point(class_scope:llm.EmbedResponse)
  })
_sym_db.RegisterMessage(EmbedResponse)

_LLM = DESCRIPTOR.services_by_name['LLM']
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  _COMPLETIONREQUEST._serialized_start=19
  _COMPLETIONREQUEST._serialized_end=170
  _COMPLETIONRESPONSE._serialized_start=172
  _COMPLETIONRESPONSE._serialized_end=210
  _EMBEDREQUEST._serialized_start=212
  _EMBEDREQUEST._serialized_end=242
  _EMBEDRESPONSE._serialized_start=244
  _EMBEDRESPONSE._serialized_end=274
  _LLM._serialized_start=276
  _LLM._serialized_end=398
# @@protoc_insertion_point(module_scope)
