{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8160a166",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "303afbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch\n",
      "import lightning\n",
      "import transformers\n",
      "import datasets\n",
      "import model\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"import torch\")\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"import lightning\")\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor, Callback\n",
    "from lightning.pytorch import Trainer, LightningModule\n",
    "\n",
    "print(\"import transformers\")\n",
    "from transformers.models.gpt2 import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Config\n",
    "\n",
    "print(\"import datasets\")\n",
    "from datasets import load_dataset\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "print(\"import model\")\n",
    "import model\n",
    "import knn\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b4feb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading teacher\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae96e258d994cddad8bca3d384f055e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15bfc3729fe4bee880a29d3ee35d9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc034e6974c40db8f062b2921767fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "teacher_name = \"gpt2-large\"\n",
    "\n",
    "print(\"Loading teacher\")\n",
    "\n",
    "teacher = GPT2LMHeadModel.from_pretrained(teacher_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(teacher_name)\n",
    "config = teacher.config\n",
    "print(\"Done\")z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "730cf3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Found cached dataset ag_news (/home/consciouscode/.cache/huggingface/datasets/ag_news/all/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ce6643379b4d5bae18bd783901c4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/consciouscode/.cache/huggingface/datasets/ag_news/all/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-7ad8216966f98598.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"kNN memory\")\n",
    "memory = knn.KNNMemory(\"orin\", config.n_embd, config.n_embd)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31da6742",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                    | Params\n",
      "----------------------------------------------------------\n",
      "0 | teacher_model | GPT2LMHeadModel         | 124 M \n",
      "1 | student_model | InfoDistilleryGPT2Model | 66.9 M\n",
      "2 | distill_loss  | KLDivLoss               | 0     \n",
      "3 | ce_loss       | CrossEntropyLoss        | 0     \n",
      "----------------------------------------------------------\n",
      "191 M     Trainable params\n",
      "384       Non-trainable params\n",
      "191 M     Total params\n",
      "765.476   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2b2cefda734dcb9ebeab56dbf22976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids [tensor([22401,  9914, 44142, 31206, 44142,  1273, 26788, 42268],\n",
      "       device='cuda:0'), tensor([  520,   306,   290, 11023,  4536,  3320, 34068,  2431],\n",
      "       device='cuda:0'), tensor([   13,   293, 18493,   912, 48701,  5268, 21710,   905],\n",
      "       device='cuda:0'), tensor([15682, 29403, 10130, 11474,   284,  3205,   287, 17873],\n",
      "       device='cuda:0'), tensor([30358, 24324,   520,  1475,   477,    11, 26603,   625],\n",
      "       device='cuda:0'), tensor([ 5157,   446,  3320,  3742,    12,   887,  6119, 10610],\n",
      "       device='cuda:0'), tensor([20008, 22724,     6,   422,  2435, 20173,   357,   357],\n",
      "       device='cuda:0'), tensor([  262, 43226, 30096,  8774,  1700,  6280,  2969,  2937],\n",
      "       device='cuda:0'), tensor([2619,  357,  357, 8050,   11,  406,    8, 1404], device='cuda:0'), tensor([  357, 12637, 12637, 37709, 24380,  1666,  3486,  3727],\n",
      "       device='cuda:0'), tensor([12637,     8,     8,   357,   649,   357,   532,  4792],\n",
      "       device='cuda:0'), tensor([    8,  8428,  8428, 12637, 36292, 12637, 41059,    13],\n",
      "       device='cuda:0'), tensor([8428,  532,  532,    8,  284,    8,  286,  785], device='cuda:0'), tensor([  532, 15348,  1406,  8428,  1294,  8428,   262,     8],\n",
      "       device='cuda:0'), tensor([10073,  4896,  1723,   532,  3773,   532,  3277,  1294],\n",
      "       device='cuda:0'), tensor([   12,  4081, 14897, 30756,   357,   520,   338,  1404],\n",
      "       device='cuda:0'), tensor([ 7255, 35982,  4536,   423, 17449,  3320,  6308,  3727],\n",
      "       device='cuda:0'), tensor([  364,   293,  5556, 27771,     8,  4444,  1637,  4792],\n",
      "       device='cuda:0'), tensor([   11,  4912, 18572,  3056,  8916,  4622,  1910,    13],\n",
      "       device='cuda:0'), tensor([ 5007,    11,    59, 10784,   532,  2440, 13584,   785],\n",
      "       device='cuda:0'), tensor([ 3530,    59, 10755,    59,   309,   319,  5153,   532],\n",
      "       device='cuda:0'), tensor([  338,  4758,   262, 44041,   451,  3217,  3214, 26702],\n",
      "       device='cuda:0'), tensor([45215,   468,  3773,   422,  8272,    59,   416,  4200],\n",
      "       device='cuda:0'), tensor([   59,   257,   290,   262,   995,  4360,   220, 31318],\n",
      "       device='cuda:0'), tensor([3903, 8507,  262, 1388, 3056, 9658, 1303,  736], device='cuda:0'), tensor([  286,   329, 19360, 11523,  4536,  1474,  2623,   257],\n",
      "       device='cuda:0'), tensor([14764,  1642,   329,   287,    11, 34119,    26,  1643],\n",
      "       device='cuda:0'), tensor([   12,   880, 12042,  8372, 23126,   329,    16,   287],\n",
      "       device='cuda:0'), tensor([ 948,   12,  389, 3908, 1359,  262,   13, 2901], device='cuda:0'), tensor([   77, 16514,  2938,   706,  4406,   614,  1558,    11],\n",
      "       device='cuda:0'), tensor([ 873,  276,  284,   59,  290,  355, 2997,  290], device='cuda:0'), tensor([   11,   290,    59, 32683,   965,  3056,   287,   649],\n",
      "       device='cuda:0'), tensor([  389, 10491, 33255,  3751,  1397,  4536,   262,  3667],\n",
      "       device='cuda:0'), tensor([ 4379,    59,   625,   257, 29608, 36061,  3452,   329],\n",
      "       device='cuda:0'), tensor([ 4077,  3642,   262, 14034,    11,  1613,  1285,  1693],\n",
      "       device='cuda:0'), tensor([  757, 46927,  4283, 21085,  1944,   220,   284,  1203],\n",
      "       device='cuda:0'), tensor([  13, 5341, 1910,  714,  257, 1303,  220, 4034], device='cuda:0'), tensor([  15,  287, 1306, 5587,  649, 2623, 1303, 3214], device='cuda:0'), tensor([  15,  262, 1285,   59, 3034,   26, 2623,  938], device='cuda:0'), tensor([   15,  3761,  1141, 10745, 36292,  3510,    26,  1285],\n",
      "       device='cuda:0'), tensor([  15, 2831,  262, 6410, 8523,   59,   23,   11], device='cuda:0'), tensor([  15,   11, 6795,   11, 1115,   64, 2920,  262], device='cuda:0'), tensor([  15,  468,  286,  281, 1933, 9036,   13, 1230], device='cuda:0'), tensor([   15, 12703,   262,  3056,   878,    11,  4089,   531],\n",
      "       device='cuda:0'), tensor([   15,  4624,    59,  1743,   262, 11677, 12989,  3635],\n",
      "       device='cuda:0'), tensor([   15,    59, 16345,   531,  1294,   889,    11,    11],\n",
      "       device='cuda:0'), tensor([   15,   896,   647,   319,  4787,   257,   262, 12739],\n",
      "       device='cuda:0'), tensor([   15, 29222,   466,  3909,  7024,  3967, 20877,   262],\n",
      "       device='cuda:0'), tensor([   15,   319,   335,    13,    13, 19360,  5834,  3773],\n",
      "       device='cuda:0'), tensor([   15,  1194, 45241,    15,    15,   422,  5136,   318],\n",
      "       device='cuda:0'), tensor([   15,   636,    13,    15,    15,  3644,   531, 10068],\n",
      "       device='cuda:0'), tensor([   15,   286,    15,    15,    15, 16009,  3635,   422],\n",
      "       device='cuda:0'), tensor([ 15, 262,  15,  15,  15,  59,  13, 257], device='cuda:0'), tensor([   15,  1910,    15,    15,    15,    35,    15, 49304],\n",
      "       device='cuda:0'), tensor([   15,    13,    15,    15,    15,   695,    15, 31647],\n",
      "       device='cuda:0'), tensor([   15,    15,    15,    15,    15,  3457,    15, 37758],\n",
      "       device='cuda:0'), tensor([15, 15, 15, 15, 15, 13, 15, 13], device='cuda:0'), tensor([ 15,  15,  15,  15,  15, 357,  15,  15], device='cuda:0'), tensor([  15,   15,   15,   15,   15, 7206,   15,   15], device='cuda:0'), tensor([  15,   15,   15,   15,   15, 3069,   15,   15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 13, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 46, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15,  8, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0'), tensor([15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 │   </span>LearningRateMonitor(logging_interval=<span style=\"color: #808000; text-decoration-color: #808000\">'step'</span>),                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 │   </span>FrequentCheckpoint(save_steps=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1000</span>, output_dir=<span style=\"color: #808000; text-decoration-color: #808000\">\"checkpoints\"</span>)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>])                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 9 trainer.fit(model, dataloader)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">520</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 517 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 518 │   │   </span>model = _maybe_unwrap_optimized(model)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 519 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy._lightning_module = model                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 520 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>call._call_and_handle_interrupt(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 521 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 522 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 523 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">call.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">44</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_and_handle_interrupt</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trainer.strategy.launcher <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 42 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 44 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer_fn(*args, **kwargs)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 46 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> _TunerExitException:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 47 │   │   </span>_call_teardown_hook(trainer)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">559</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_fit_impl</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 556 │   │   │   </span>model_provided=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 557 │   │   │   </span>model_connected=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lightning_module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 558 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 559 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._run(model, ckpt_path=ckpt_path)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 560 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 561 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.stopped                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 562 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">935</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_run</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 932 │   │   # ----------------------------</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 933 │   │   # RUN THE TRAINER</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 934 │   │   # ----------------------------</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 935 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>results = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._run_stage()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 936 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 937 │   │   # ----------------------------</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 938 │   │   # POST-Training CLEAN UP</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">978</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_run_stage</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 975 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> isolate_rng():                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 976 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._run_sanity_check()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 977 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.autograd.set_detect_anomaly(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._detect_anomaly):                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 978 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fit_loop.run()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 979 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 980 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Unexpected state {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 981 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fit_loop.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">201</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.done:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.on_advance_start()                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>201 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.advance()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.on_advance_end()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._restarting = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">204 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">StopIteration</span>:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fit_loop.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">354</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">advance</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">351 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._data_fetcher <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">352 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._data_fetcher.setup(combined_loader)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">353 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.profiler.profile(<span style=\"color: #808000; text-decoration-color: #808000\">\"run_training_epoch\"</span>):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>354 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.epoch_loop.run(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._data_fetcher)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">355 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">356 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on_advance_end</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">357 │   │   </span>trainer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">training_epoch_l</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">oop.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">133</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">130 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.on_run_start(data_fetcher)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.done:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>133 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.advance(data_fetcher)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.on_advance_end()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._restarting = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">StopIteration</span>:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">training_epoch_l</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">oop.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">218</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">advance</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> trainer.profiler.profile(<span style=\"color: #808000; text-decoration-color: #808000\">\"run_training_batch\"</span>):                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">216 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trainer.lightning_module.automatic_optimization:                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">217 │   │   │   │   │   # in automatic optimization, there can only be one optimizer</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>218 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>batch_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.automatic_optimization.run(trainer.optimizers[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">220 │   │   │   │   │   </span>batch_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.manual_optimization.run(kwargs)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">221 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">aut</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">omatic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">185</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">182 │   │   # ------------------------------</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">183 │   │   # gradient update with accumulated gradients</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">184 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>185 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._optimizer_step(kwargs.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"batch_idx\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>), closure)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">186 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">187 │   │   </span>result = closure.consume_result()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">188 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> result.loss <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">aut</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">omatic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">261</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_optimizer_step</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optim_progress.optimizer.step.increment_ready()                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">259 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260 │   │   # model hook</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>261 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>call._call_lightning_module_hook(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">262 │   │   │   </span>trainer,                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">263 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"optimizer_step\"</span>,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">264 │   │   │   </span>trainer.current_epoch,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">call.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">142</span> in <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_lightning_module_hook</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   </span>pl_module._current_fx_name = hook_name                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> trainer.profiler.profile(<span style=\"color: #808000; text-decoration-color: #808000\">f\"[LightningModule]{</span>pl_module.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}.{</span>hoo   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>142 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = fn(*args, **kwargs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 │   # restore current_fx when nested context</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">145 │   </span>pl_module._current_fx_name = prev_fx_name                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1266</span> in <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">optimizer_step</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1263 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">for pg in optimizer.param_groups:</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1264 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">pg[\"lr\"] = lr_scale * self.learning_rate</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1265 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1266 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>optimizer.step(closure=optimizer_closure)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1267 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1268 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">optimizer_zero_grad</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, epoch: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>, batch_idx: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>, optimizer: Optimizer) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">N</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1269 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Override this method to change the default behaviour of ``optimizer.zero_grad</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">158</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">155 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> MisconfigurationException(<span style=\"color: #808000; text-decoration-color: #808000\">\"When `optimizer.step(closure)` is called, t</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._strategy <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>158 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>step_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._strategy.optimizer_step(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._optimizer, closure, **kwargs)    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._on_after_step()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">strategy.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">224</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">optimizer_step</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">221 │   │   </span>model = model <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lightning_module                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">222 │   │   # TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">223 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(model, pl.LightningModule)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>224 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.precision_plugin.optimizer_step(optimizer, model=model, closure=clos   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">226 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_setup_model_and_optimizers</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, model: Module, optimizers: List[Optimizer]) -&gt;   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Setup a model and multiple optimizers together.</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">prec</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ision_plugin.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">114</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">optimizer_step</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   </span>) -&gt; Any:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Hook to run the optimizer step.\"\"\"</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   │   </span>closure = partial(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._wrap_closure, model, optimizer, closure)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>114 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> optimizer.step(closure=closure, **kwargs)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_clip_gradients</span>(                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">280</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">277 │   │   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>func<span style=\"color: #808000; text-decoration-color: #808000\">} must return None or a tuple of (</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">278 │   │   │   │   │   │   │   │   │   │   │      </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"but got {</span>result<span style=\"color: #808000; text-decoration-color: #808000\">}.\"</span>)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">279 │   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>280 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>out = func(*args, **kwargs)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">281 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._optimizer_step_code()                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">282 │   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">283 │   │   │   │   # call optimizer step post hooks</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">33</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_use_grad</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 30 │   │   </span>prev_grad = torch.is_grad_enabled()                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 31 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 32 │   │   │   </span>torch.set_grad_enabled(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.defaults[<span style=\"color: #808000; text-decoration-color: #808000\">'differentiable'</span>])                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 33 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>ret = func(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 34 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 35 │   │   │   </span>torch.set_grad_enabled(prev_grad)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 36 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> ret                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/torch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">adam.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">121</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 │   │   </span>loss = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> closure <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.enable_grad():                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>121 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>loss = closure()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> group <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.param_groups:                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 │   │   │   </span>params_with_grad = []                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">prec</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ision_plugin.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">101</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrap_closure</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">The closure (generally) runs ``backward`` so this allows inspecting gradients in</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>101 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>closure_result = closure()                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._after_closure(model, optimizer)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">103 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> closure_result                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">104 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">aut</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">omatic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">140</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> step_output                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args: Any, **kwargs: Any) -&gt; Optional[Tensor]:                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>140 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._result = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.closure(*args, **kwargs)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._result.loss                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">aut</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">omatic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">126</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">closure</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._zero_grad_fn = zero_grad_fn                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">closure</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args: Any, **kwargs: Any) -&gt; ClosureResult:                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>126 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>step_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._step_fn()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> step_output.closure_loss <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.warning_cache.warn(<span style=\"color: #808000; text-decoration-color: #808000\">\"`training_step` returned `None`. If this was on pur</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">aut</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">omatic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">308</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_training_step</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">305 │   │   </span>trainer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">306 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">307 │   │   # manually capture logged metrics</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>308 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>training_step_output = call._call_strategy_hook(trainer, <span style=\"color: #808000; text-decoration-color: #808000\">\"training_step\"</span>, *kwarg   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">309 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.strategy.post_training_step()                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">310 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">311 │   │   </span>result = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.output_result_cls.from_training_step_output(training_step_output,    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">call.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">288</span> in <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_strategy_hook</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">285 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">286 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">287 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> trainer.profiler.profile(<span style=\"color: #808000; text-decoration-color: #808000\">f\"[Strategy]{</span>trainer.strategy.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}.{</span>hoo   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>288 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = fn(*args, **kwargs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">289 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">290 │   # restore current_fx when nested context</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">291 │   </span>pl_module._current_fx_name = prev_fx_name                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">strategy.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">366</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">363 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">364 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.precision_plugin.train_step_context():                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">365 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model, TrainingStep)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>366 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model.training_step(*args, **kwargs)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">367 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">368 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">post_training_step</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">369 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">pass</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">28</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 │   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 │   │   # Teacher model output</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>28 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>teacher_logits = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.teacher_model(input_ids=input_ids, attention_mask=atte    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 │   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 │   │   # Student model output</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 │   │   </span>student_logits, hidden = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>(input_ids, attention_mask)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1075</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1072 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1073 │   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1074 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1075 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>transformer_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transformer(                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1076 │   │   │   </span>input_ids,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1077 │   │   │   </span>past_key_values=past_key_values,                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1078 │   │   │   </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/consciouscode/.local/lib/python3.10/site-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">779</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 776 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> input_ids <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> inputs_embeds <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 777 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"You cannot specify both input_ids and inputs_embeds at the</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 778 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> input_ids <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 779 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>input_shape = input_ids.size()                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 780 │   │   │   </span>input_ids = input_ids.view(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, input_shape[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>])                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 781 │   │   │   </span>batch_size = input_ids.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 782 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> inputs_embeds <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'list'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'size'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m9\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   \u001b[0mLearningRateMonitor(logging_interval=\u001b[33m'\u001b[0m\u001b[33mstep\u001b[0m\u001b[33m'\u001b[0m),                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   \u001b[0mFrequentCheckpoint(save_steps=\u001b[94m1000\u001b[0m, output_dir=\u001b[33m\"\u001b[0m\u001b[33mcheckpoints\u001b[0m\u001b[33m\"\u001b[0m)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m])                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 9 trainer.fit(model, dataloader)                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m520\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mfit\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 517 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 518 \u001b[0m\u001b[2m│   │   \u001b[0mmodel = _maybe_unwrap_optimized(model)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 519 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy._lightning_module = model                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 520 \u001b[2m│   │   \u001b[0mcall._call_and_handle_interrupt(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 521 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, \u001b[96mself\u001b[0m._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 522 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 523 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/\u001b[0m\u001b[1;33mcall.py\u001b[0m:\u001b[94m44\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_and_handle_interrupt\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m trainer.strategy.launcher \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 44 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer_fn(*args, **kwargs)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m _TunerExitException:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 47 \u001b[0m\u001b[2m│   │   \u001b[0m_call_teardown_hook(trainer)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m559\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_fit_impl\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 556 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_provided=\u001b[94mTrue\u001b[0m,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 557 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_connected=\u001b[96mself\u001b[0m.lightning_module \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m,                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 558 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 559 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._run(model, ckpt_path=ckpt_path)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 560 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 561 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.state.stopped                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 562 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.training = \u001b[94mFalse\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m935\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_run\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 932 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# ----------------------------\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 933 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# RUN THE TRAINER\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 934 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# ----------------------------\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 935 \u001b[2m│   │   \u001b[0mresults = \u001b[96mself\u001b[0m._run_stage()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 936 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 937 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# ----------------------------\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 938 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# POST-Training CLEAN UP\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m978\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_run_stage\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 975 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m isolate_rng():                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 976 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._run_sanity_check()                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 977 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.autograd.set_detect_anomaly(\u001b[96mself\u001b[0m._detect_anomaly):                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 978 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.fit_loop.run()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 979 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mNone\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 980 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mUnexpected state \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.state\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 981 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/\u001b[0m\u001b[1;33mfit_loop.py\u001b[0m:\u001b[94m201\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mrun\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.done:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.on_advance_start()                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m201 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.advance()                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.on_advance_end()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._restarting = \u001b[94mFalse\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m204 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mStopIteration\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/\u001b[0m\u001b[1;33mfit_loop.py\u001b[0m:\u001b[94m354\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92madvance\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m351 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m._data_fetcher \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m352 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._data_fetcher.setup(combined_loader)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m353 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.trainer.profiler.profile(\u001b[33m\"\u001b[0m\u001b[33mrun_training_epoch\u001b[0m\u001b[33m\"\u001b[0m):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m354 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.epoch_loop.run(\u001b[96mself\u001b[0m._data_fetcher)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m355 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m356 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mon_advance_end\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[94mNone\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m357 \u001b[0m\u001b[2m│   │   \u001b[0mtrainer = \u001b[96mself\u001b[0m.trainer                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/\u001b[0m\u001b[1;33mtraining_epoch_l\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33moop.py\u001b[0m:\u001b[94m133\u001b[0m in \u001b[92mrun\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m130 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.on_run_start(data_fetcher)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.done:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m133 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.advance(data_fetcher)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.on_advance_end()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._restarting = \u001b[94mFalse\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mStopIteration\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/\u001b[0m\u001b[1;33mtraining_epoch_l\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33moop.py\u001b[0m:\u001b[94m218\u001b[0m in \u001b[92madvance\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m trainer.profiler.profile(\u001b[33m\"\u001b[0m\u001b[33mrun_training_batch\u001b[0m\u001b[33m\"\u001b[0m):                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m216 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m trainer.lightning_module.automatic_optimization:                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m217 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# in automatic optimization, there can only be one optimizer\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m218 \u001b[2m│   │   │   │   │   \u001b[0mbatch_output = \u001b[96mself\u001b[0m.automatic_optimization.run(trainer.optimizers[\u001b[94m0\u001b[0m]   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m219 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m220 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mbatch_output = \u001b[96mself\u001b[0m.manual_optimization.run(kwargs)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m221 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/\u001b[0m\u001b[1;33maut\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33momatic.py\u001b[0m:\u001b[94m185\u001b[0m in \u001b[92mrun\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m182 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# ------------------------------\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m183 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# gradient update with accumulated gradients\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m184 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m185 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._optimizer_step(kwargs.get(\u001b[33m\"\u001b[0m\u001b[33mbatch_idx\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94m0\u001b[0m), closure)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m186 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m187 \u001b[0m\u001b[2m│   │   \u001b[0mresult = closure.consume_result()                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m188 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m result.loss \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/\u001b[0m\u001b[1;33maut\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33momatic.py\u001b[0m:\u001b[94m261\u001b[0m in \u001b[92m_optimizer_step\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m258 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.optim_progress.optimizer.step.increment_ready()                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m259 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# model hook\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m261 \u001b[2m│   │   \u001b[0mcall._call_lightning_module_hook(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m262 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrainer,                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m263 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33moptimizer_step\u001b[0m\u001b[33m\"\u001b[0m,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m264 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrainer.current_epoch,                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/\u001b[0m\u001b[1;33mcall.py\u001b[0m:\u001b[94m142\u001b[0m in \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_lightning_module_hook\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   \u001b[0mpl_module._current_fx_name = hook_name                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m trainer.profiler.profile(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m[LightningModule]\u001b[0m\u001b[33m{\u001b[0mpl_module.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m{\u001b[0mhoo   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m142 \u001b[2m│   │   \u001b[0moutput = fn(*args, **kwargs)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# restore current_fx when nested context\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m145 \u001b[0m\u001b[2m│   \u001b[0mpl_module._current_fx_name = prev_fx_name                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/core/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1266\u001b[0m in \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92moptimizer_step\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1263 \u001b[0m\u001b[2;33m│   │   │   │   │   \u001b[0m\u001b[33mfor pg in optimizer.param_groups:\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1264 \u001b[0m\u001b[2;33m│   │   │   │   │   │   \u001b[0m\u001b[33mpg[\"lr\"] = lr_scale * self.learning_rate\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1265 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1266 \u001b[2m│   │   \u001b[0moptimizer.step(closure=optimizer_closure)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1267 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1268 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92moptimizer_zero_grad\u001b[0m(\u001b[96mself\u001b[0m, epoch: \u001b[96mint\u001b[0m, batch_idx: \u001b[96mint\u001b[0m, optimizer: Optimizer) -> \u001b[94mN\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1269 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Override this method to change the default behaviour of ``optimizer.zero_grad\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/core/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m158\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mstep\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m MisconfigurationException(\u001b[33m\"\u001b[0m\u001b[33mWhen `optimizer.step(closure)` is called, t\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m._strategy \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m158 \u001b[2m│   │   \u001b[0mstep_output = \u001b[96mself\u001b[0m._strategy.optimizer_step(\u001b[96mself\u001b[0m._optimizer, closure, **kwargs)    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._on_after_step()                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/\u001b[0m\u001b[1;33mstrategy.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m224\u001b[0m in \u001b[92moptimizer_step\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m221 \u001b[0m\u001b[2m│   │   \u001b[0mmodel = model \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.lightning_module                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m222 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m223 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96misinstance\u001b[0m(model, pl.LightningModule)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m224 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.precision_plugin.optimizer_step(optimizer, model=model, closure=clos   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m225 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_setup_model_and_optimizers\u001b[0m(\u001b[96mself\u001b[0m, model: Module, optimizers: List[Optimizer]) ->   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Setup a model and multiple optimizers together.\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/\u001b[0m\u001b[1;33mprec\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mision_plugin.py\u001b[0m:\u001b[94m114\u001b[0m in \u001b[92moptimizer_step\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   \u001b[0m) -> Any:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0mclosure = partial(\u001b[96mself\u001b[0m._wrap_closure, model, optimizer, closure)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m optimizer.step(closure=closure, **kwargs)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_clip_gradients\u001b[0m(                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m,                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/torch/optim/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m280\u001b[0m in \u001b[92mwrapper\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m277 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mfunc\u001b[33m}\u001b[0m\u001b[33m must return None or a tuple of (\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m278 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │      \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbut got \u001b[0m\u001b[33m{\u001b[0mresult\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m279 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m280 \u001b[2m│   │   │   │   \u001b[0mout = func(*args, **kwargs)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._optimizer_step_code()                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# call optimizer step post hooks\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/torch/optim/\u001b[0m\u001b[1;33moptimizer.py\u001b[0m:\u001b[94m33\u001b[0m in \u001b[92m_use_grad\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 30 \u001b[0m\u001b[2m│   │   \u001b[0mprev_grad = torch.is_grad_enabled()                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 31 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 32 \u001b[0m\u001b[2m│   │   │   \u001b[0mtorch.set_grad_enabled(\u001b[96mself\u001b[0m.defaults[\u001b[33m'\u001b[0m\u001b[33mdifferentiable\u001b[0m\u001b[33m'\u001b[0m])                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 33 \u001b[2m│   │   │   \u001b[0mret = func(\u001b[96mself\u001b[0m, *args, **kwargs)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 34 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 35 \u001b[0m\u001b[2m│   │   │   \u001b[0mtorch.set_grad_enabled(prev_grad)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 36 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m ret                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/torch/optim/\u001b[0m\u001b[1;33madam.py\u001b[0m:\u001b[94m121\u001b[0m in \u001b[92mstep\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   \u001b[0mloss = \u001b[94mNone\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m closure \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.enable_grad():                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m121 \u001b[2m│   │   │   │   \u001b[0mloss = closure()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m group \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.param_groups:                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   │   │   \u001b[0mparams_with_grad = []                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/\u001b[0m\u001b[1;33mprec\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mision_plugin.py\u001b[0m:\u001b[94m101\u001b[0m in \u001b[92m_wrap_closure\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mThe closure (generally) runs ``backward`` so this allows inspecting gradients in\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mconsistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m101 \u001b[2m│   │   \u001b[0mclosure_result = closure()                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m102 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._after_closure(model, optimizer)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m closure_result                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m104 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/\u001b[0m\u001b[1;33maut\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33momatic.py\u001b[0m:\u001b[94m140\u001b[0m in \u001b[92m__call__\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m step_output                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, *args: Any, **kwargs: Any) -> Optional[Tensor]:                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m140 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._result = \u001b[96mself\u001b[0m.closure(*args, **kwargs)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._result.loss                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/\u001b[0m\u001b[1;33maut\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33momatic.py\u001b[0m:\u001b[94m126\u001b[0m in \u001b[92mclosure\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._zero_grad_fn = zero_grad_fn                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mclosure\u001b[0m(\u001b[96mself\u001b[0m, *args: Any, **kwargs: Any) -> ClosureResult:                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m126 \u001b[2m│   │   \u001b[0mstep_output = \u001b[96mself\u001b[0m._step_fn()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m127 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m step_output.closure_loss \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.warning_cache.warn(\u001b[33m\"\u001b[0m\u001b[33m`training_step` returned `None`. If this was on pur\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/\u001b[0m\u001b[1;33maut\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33momatic.py\u001b[0m:\u001b[94m308\u001b[0m in \u001b[92m_training_step\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m305 \u001b[0m\u001b[2m│   │   \u001b[0mtrainer = \u001b[96mself\u001b[0m.trainer                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m306 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m307 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# manually capture logged metrics\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m308 \u001b[2m│   │   \u001b[0mtraining_step_output = call._call_strategy_hook(trainer, \u001b[33m\"\u001b[0m\u001b[33mtraining_step\u001b[0m\u001b[33m\"\u001b[0m, *kwarg   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m309 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.trainer.strategy.post_training_step()                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m310 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m311 \u001b[0m\u001b[2m│   │   \u001b[0mresult = \u001b[96mself\u001b[0m.output_result_cls.from_training_step_output(training_step_output,    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/\u001b[0m\u001b[1;33mcall.py\u001b[0m:\u001b[94m288\u001b[0m in \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_strategy_hook\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m285 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m286 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m287 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m trainer.profiler.profile(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m[Strategy]\u001b[0m\u001b[33m{\u001b[0mtrainer.strategy.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m{\u001b[0mhoo   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m288 \u001b[2m│   │   \u001b[0moutput = fn(*args, **kwargs)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m289 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m290 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# restore current_fx when nested context\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m291 \u001b[0m\u001b[2m│   \u001b[0mpl_module._current_fx_name = prev_fx_name                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/\u001b[0m\u001b[1;33mstrategy.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m366\u001b[0m in \u001b[92mtraining_step\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m363 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m364 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.precision_plugin.train_step_context():                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m365 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96misinstance\u001b[0m(\u001b[96mself\u001b[0m.model, TrainingStep)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m366 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.model.training_step(*args, **kwargs)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mpost_training_step\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[94mNone\u001b[0m:                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m369 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mpass\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtraining_step\u001b[0m:\u001b[94m28\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m25 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Teacher model output\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m27 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m28 \u001b[2m│   │   │   \u001b[0mteacher_logits = \u001b[96mself\u001b[0m.teacher_model(input_ids=input_ids, attention_mask=atte    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Student model output\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m│   │   \u001b[0mstudent_logits, hidden = \u001b[96mself\u001b[0m(input_ids, attention_mask)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1075\u001b[0m in \u001b[92mforward\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1072 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1073 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1074 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1075 \u001b[2m│   │   \u001b[0mtransformer_outputs = \u001b[96mself\u001b[0m.transformer(                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1076 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1077 \u001b[0m\u001b[2m│   │   │   \u001b[0mpast_key_values=past_key_values,                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1078 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/consciouscode/.local/lib/python3.10/site-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m779\u001b[0m in \u001b[92mforward\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 776 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m input_ids \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m inputs_embeds \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 777 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mYou cannot specify both input_ids and inputs_embeds at the\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 778 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m input_ids \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 779 \u001b[2m│   │   │   \u001b[0minput_shape = input_ids.size()                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 780 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids = input_ids.view(-\u001b[94m1\u001b[0m, input_shape[-\u001b[94m1\u001b[0m])                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 781 \u001b[0m\u001b[2m│   │   │   \u001b[0mbatch_size = input_ids.shape[\u001b[94m0\u001b[0m]                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 782 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m inputs_embeds \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'list'\u001b[0m object has no attribute \u001b[32m'size'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Begin training\")\n",
    "\n",
    "# Train the model\n",
    "model = KnowledgeDistillationModel(teacher, student, memory, tokenizer)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", max_epochs=3, callbacks = z)\n",
    "trainer.fit(model, dataloader)\n",
    "\n",
    "# Save the distilled model\n",
    "student.save_pretrained(\"distilled_gpt2\")\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\", max_epochs=3,\n",
    "    callbacks=[\n",
    "        LearningRateMonitor(logging_interval='step'),\n",
    "        FrequentCheckpoint(save_steps=1000, output_dir=\"checkpoints\")\n",
    "    ]\n",
    ")\n",
    "trainer.fit(\n",
    "    KnowledgeDistillationModule(teacher, model.InfoDistilleryLMHeadModel(student), memory),\n",
    "    datamodule=WikiText103DataModule(dataset)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
